{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "survey_res = pd.read_csv('data/survey_responses.csv', skiprows=[1, 2]) # survey responses\n",
    "\n",
    "logs1 = pd.read_csv('data/interactions.csv')     # interaction logs on rating page\n",
    "logs2 = pd.read_csv('data/vis_interactions.csv') # interaction logs on visualization page\n",
    "\n",
    "rating_history = pd.read_csv('data/rating_history.csv')   # rating history\n",
    "ratings = pd.read_csv('data/ratings.csv')                 # ratings\n",
    "\n",
    "applications = pd.read_csv('data/applications.csv')       # application information\n",
    "\n",
    "\n",
    "# get the user id for thoes who completed the survey\n",
    "user_ids = survey_res['user_id'].tolist()\n",
    "\n",
    "# filter the data to only include the users who completed the survey\n",
    "logs1 = logs1[logs1['user_id'].isin(user_ids)]\n",
    "logs1 = logs1[logs1['applicant_id'] > 0]\n",
    "logs2 = logs2[logs2['user_id'].isin(user_ids)]\n",
    "rating_history = rating_history[rating_history['user_id'].isin(user_ids)]\n",
    "ratings = ratings[ratings['user_id'].isin(user_ids)]\n",
    "\n",
    "# save filtered data\n",
    "ratings.to_csv('data/ratings.csv', index=False)\n",
    "rating_history.to_csv('data/rating_history.csv', index=False)\n",
    "logs1.to_csv('data/interactions.csv', index=False)\n",
    "logs2.to_csv('data/vis_interactions.csv', index=False)\n",
    "\n",
    "applications.rename(columns={'id': 'applicant_id'}, inplace=True)\n",
    "rating_history = pd.merge(rating_history, applications[['applicant_id', 'GENDER', 'RACE']], on='applicant_id')\n",
    "logs2_merged = pd.merge(logs2, applications[['applicant_id', 'GENDER', 'RACE']], on='applicant_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for each user, get the timestamp that they finished the tour\n",
    "tour_finished_time_stamps = {}\n",
    "for user in user_ids:\n",
    "    tour_finished_time_stamps[user] = logs2[(logs2['user_id'] == user) & (logs2['interaction_type'] == 'tourFinished')]['timestamp'].iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rating history for each user after the tour finish timestamp\n",
    "ratings_after_tour = rating_history[rating_history.apply(lambda x: x['timestamp'] > tour_finished_time_stamps[x['user_id']]/1000, axis=1)]\n",
    "\n",
    "\n",
    "# add a column to ratings for the ratings before users interacted with the visualization\n",
    "\n",
    "ratings['rating_before'] = ratings['rating']\n",
    "\n",
    "ratings.rename(columns={'rating': 'rating_after'}, inplace=True)\n",
    "\n",
    "# add a column for the rating changes\n",
    "ratings['rating_change'] = 0\n",
    "\n",
    "# iterate through each row of the ratings_after_tour\n",
    "for row in ratings_after_tour.iterrows():\n",
    "    prev_rating = rating_history[(rating_history['user_id'] == row[1]['user_id']) & \n",
    "                                 (rating_history['applicant_id'] == row[1]['applicant_id']) &\n",
    "                                 (rating_history['timestamp'] < tour_finished_time_stamps[row[1]['user_id']]/1000)]\n",
    "\n",
    "    row_id = ratings[(ratings['user_id'] == row[1]['user_id']) & (ratings['applicant_id'] == row[1]['applicant_id'])].index[0]\n",
    "    ratings.loc[row_id, 'rating_before'] = prev_rating['rating'].iloc[-1]\n",
    "    ratings.loc[row_id, 'rating_change'] = row[1]['rating'] - prev_rating['rating'].iloc[-1]\n",
    "\n",
    "    # print(\"rating change: \", ratings.loc[row_id, 'rating_change'])\n",
    "\n",
    "# save to csv\n",
    "# drop the timsstamp column\n",
    "ratings.drop(['id','add_timestamp'], axis=1, inplace=True)\n",
    "ratings.to_csv('data/ratings_with_change.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Spent Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the focus time before intervention  \n",
    "from itertools import product\n",
    "\n",
    "focus_time = pd.DataFrame(list(product(user_ids, applications['applicant_id'].tolist())), columns=['user_id', 'applicant_id'])\n",
    "focus_time['total_before'] = 0\n",
    "focus_time['total_after'] = 0\n",
    "focus_time['total_change'] = 0\n",
    "\n",
    "# get the logs before the summary page tour finished timestamp -- these interactions happened before the intervention\n",
    "logs1_before_tour = logs1[logs1.apply(lambda x: x['timestamp'] < tour_finished_time_stamps[x['user_id']], axis=1)]\n",
    "\n",
    "for user_id, logs in logs1_before_tour.groupby('user_id'):\n",
    "    intervals = {}\n",
    "    durations = []\n",
    "    \n",
    "    if logs.shape[0] > 1: # need at least 2 interactions to get an interval\n",
    "        for i in range(logs.shape[0] - 1):  \n",
    "            log1 = logs.iloc[i]\n",
    "            log2 = logs.iloc[i+1]\n",
    "\n",
    "            # Leave individual rating page, ignore the interval\n",
    "            if log1['interaction_type'] ==  'hidden' or log1['interaction_type'] == 'leave' or log1['interaction_type'] ==  'close': \n",
    "                continue\n",
    "            # The second log is page visiable , ignore the interval\n",
    "            # Usually visiable event should follows a hidden event which is handled, have this additional test incase something goes wrong such that a hidden event is not logged \n",
    "            if log2['interaction_type'] ==  'visible':\n",
    "                continue\n",
    "\n",
    "            applicant_id = log1['applicant_id'] \n",
    "            duration = (log2['timestamp'] - log1['timestamp']) / 1000.0  # in seconds\n",
    "\n",
    "            if duration > 0:\n",
    "                durations.append(duration)\n",
    "\n",
    "                if applicant_id not in intervals:\n",
    "                    intervals[applicant_id] = []\n",
    "\n",
    "                intervals[applicant_id].append({'duration': duration })\n",
    "\n",
    "    log_durations = np.log(durations)\n",
    "    Q1 = np.quantile(log_durations, .25)\n",
    "    Q3 = np.quantile(log_durations, .75)\n",
    "    IQR = Q3 -Q1\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "\n",
    "    for key, val in intervals.items():\n",
    "        if (key !=0):\n",
    "            total = 0\n",
    "            for interval in val:\n",
    "                if (np.log(interval['duration']) < upper_bound): # filter out outliers\n",
    "                    total += (interval['duration'] / 60.0)\n",
    "            \n",
    "            row_id = focus_time[(focus_time['user_id'] == user_id) & (focus_time['applicant_id'] == key)].index[0]\n",
    "            focus_time.loc[row_id, 'total_before'] = total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the focus time after intervention  \n",
    "\n",
    "# get the logs after the summary page tour finished timestamp -- these interactions happened after the intervention\n",
    "logs1_after_tour = logs1[logs1.apply(lambda x: x['timestamp'] > tour_finished_time_stamps[x['user_id']], axis=1)]\n",
    "for user_id, logs in logs1_after_tour.groupby('user_id'):\n",
    "    intervals = {}\n",
    "    durations = []\n",
    "    \n",
    "    if logs.shape[0] > 1: # need at least 2 interactions to get an interval\n",
    "        for i in range(logs.shape[0] - 1):  \n",
    "            log1 = logs.iloc[i]\n",
    "            log2 = logs.iloc[i+1]\n",
    "\n",
    "            # Leave individual rating page, ignore the interval\n",
    "            if log1['interaction_type'] ==  'hidden' or log1['interaction_type'] == 'leave' or log1['interaction_type'] ==  'close': \n",
    "                continue\n",
    "            # The second log is page visiable , ignore the interval\n",
    "            # Usually visiable event should follows a hidden event which is handled, have this additional test incase something goes wrong such that a hidden event is not logged \n",
    "            if log2['interaction_type'] ==  'visible':\n",
    "                continue\n",
    "\n",
    "            applicant_id = log1['applicant_id'] \n",
    "            duration = (log2['timestamp'] - log1['timestamp']) / 1000.0  # in seconds\n",
    "\n",
    "            if duration > 0:\n",
    "                durations.append(duration)\n",
    "\n",
    "                if applicant_id not in intervals:\n",
    "                    intervals[applicant_id] = []\n",
    "\n",
    "                intervals[applicant_id].append({'duration': duration })\n",
    "\n",
    "    for key, val in intervals.items():\n",
    "\n",
    "        row_id = focus_time[(focus_time['user_id'] == user_id) & (focus_time['applicant_id'] == key)].index[0]\n",
    "        total_time = sum([i['duration'] for i in val]) / 60.0\n",
    "        focus_time.loc[row_id, 'total_change'] = total_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_time['total_after'] = focus_time['total_before'] + focus_time['total_change']\n",
    "focus_time.to_csv('data/focus_time_with_change.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLick interaction count on time spent plots:  14\n",
      "Hover interaction count on time spent plots:  418\n",
      "\n",
      "CLick interaction count on competitivenss rating plots:  11\n",
      "Hover interaction count on competitivenss rating plots:  208\n",
      "\n",
      "CLick interaction count on applicant list:  54\n",
      "Hover interaction count on applicant list:  1441\n"
     ]
    }
   ],
   "source": [
    "# get click and hover interactions\n",
    "logs2_click = logs2_merged[logs2_merged['interaction_type'] == 'click' ]\n",
    "logs2_hover = logs2_merged[logs2_merged['interaction_type'] == 'hover']\n",
    "\n",
    "# count by component\n",
    "# print(\"Click interaction count by component:\\n\",logs2_click['element'].value_counts())\n",
    "\n",
    "# print(\"\\nHover interaction count by component:\\n\",logs2_hover['element'].value_counts())\n",
    "\n",
    "print(\"\\nCLick interaction count on time spent plots: \", logs2_click[logs2_click['element'].isin(['raceTimePoints', 'genderTimePoints'])].shape[0])\n",
    "print(\"Hover interaction count on time spent plots: \", logs2_hover[logs2_hover['element'].isin(['time_race', 'time_gender'])].shape[0])\n",
    "\n",
    "print(\"\\nCLick interaction count on competitivenss rating plots: \", logs2_click[logs2_click['element'].isin(['raceRatingPoints', 'genderRatingPoints'])].shape[0])\n",
    "print(\"Hover interaction count on competitivenss rating plots: \", logs2_hover[logs2_hover['element'].isin(['rating_race', 'rating_gender'])].shape[0])\n",
    "\n",
    "print(\"\\nCLick interaction count on applicant list: \", logs2_click[logs2_click['element'] == 'applicantList'].shape[0])\n",
    "print(\"Hover interaction count on applicant list: \", logs2_hover[logs2_hover['element'] == 'applicantList'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revisits:  79\n",
      "Number of users who revisited the applicants:  46\n",
      "Min, max, average number of applicants revisted by each user:  1 7 2\n"
     ]
    }
   ],
   "source": [
    "#  get click interactions on the applicants\n",
    "revisits = logs2_click[~logs2_click['element'].isin(['comment', 'recommendation'])]\n",
    "\n",
    "# total clicks (revisits) on the applicants\n",
    "print(\"Total revisits: \", revisits.shape[0])\n",
    "\n",
    "# number of users who revisited the applicants\n",
    "print(\"Number of users who revisited the applicants: \", len(revisits['user_id'].unique()))\n",
    "\n",
    "# number of applicants revisted by each user\n",
    "print(\"Min, max, average number of applicants revisted by each user: \", revisits.groupby('user_id')['applicant_id'].nunique().min(),\n",
    "      revisits.groupby('user_id')['applicant_id'].nunique().max(),\n",
    "      round(revisits.groupby('user_id')['applicant_id'].nunique().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hover interaction count on the Time Spent by Gender plot: \n",
      " GENDER\n",
      "Female        118\n",
      "Male           73\n",
      "Non-binary     92\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "CLick interaction count on the Time Spent by Gender plot: \n",
      " GENDER\n",
      "Female        3\n",
      "Male          3\n",
      "Non-binary    5\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "Hover interaction count on the Competitiveness Rating by Gender plot: \n",
      " GENDER\n",
      "Female        45\n",
      "Male          42\n",
      "Non-binary    38\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "CLick interaction count on the Competitiveness Rating by Gender plot: \n",
      " GENDER\n",
      "Female        1\n",
      "Male          5\n",
      "Non-binary    2\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "Hover interaction count on the Time Spent by Race plot: \n",
      " RACE\n",
      "Black    79\n",
      "White    56\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "CLick interaction count on the Time Spent by Race plot: \n",
      " RACE\n",
      "Black    3\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "Hover interaction count on the Competitiveness Rating by Race plot: \n",
      " RACE\n",
      "Black    45\n",
      "White    38\n",
      "Name: applicant_id, dtype: int64\n",
      "\n",
      "CLick interaction count on the Competitiveness Rating by Race plot: \n",
      " RACE\n",
      "Black    2\n",
      "White    1\n",
      "Name: applicant_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# hover and click interactions on the Time Spent by Gender and Competitiveness Rating by Gender plots\n",
    "\n",
    "print(\"Hover interaction count on the Time Spent by Gender plot: \\n\",\n",
    "      logs2_hover[logs2_hover['element'] == 'time_gender'].groupby(['GENDER'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nCLick interaction count on the Time Spent by Gender plot: \\n\",\n",
    "      revisits[revisits['element'] == 'genderTimePoints'].groupby(['GENDER'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nHover interaction count on the Competitiveness Rating by Gender plot: \\n\",\n",
    "      logs2_hover[logs2_hover['element'] == 'rating_gender'].groupby(['GENDER'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nCLick interaction count on the Competitiveness Rating by Gender plot: \\n\",\n",
    "      revisits[revisits['element'] == 'genderRatingPoints'].groupby(['GENDER'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "#  hover and interactions on the Time Spent by Race and Competitiveness Rating by Race plots\n",
    "print(\"\\nHover interaction count on the Time Spent by Race plot: \\n\",\n",
    "      logs2_hover[logs2_hover['element'] == 'time_race'].groupby(['RACE'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nCLick interaction count on the Time Spent by Race plot: \\n\",\n",
    "      revisits[revisits['element'] == 'raceTimePoints'].groupby(['RACE'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nHover interaction count on the Competitiveness Rating by Race plot: \\n\",\n",
    "      logs2_hover[logs2_hover['element'] == 'rating_race'].groupby(['RACE'])['applicant_id'].count()\n",
    ")\n",
    "\n",
    "print(\"\\nCLick interaction count on the Competitiveness Rating by Race plot: \\n\",\n",
    "      revisits[revisits['element'] == 'raceRatingPoints'].groupby(['RACE'])['applicant_id'].count()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings and time spents for the applicants who were revisited\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "logs2_hover['mean_time'] = logs2_hover['user_id'].map(focus_time.groupby('user_id')['total_before'].mean())\n",
    "logs2_hover['mean_rating'] = logs2_hover['user_id'].map(ratings.groupby('user_id')['rating_before'].median())\n",
    "\n",
    "revisits['mean_time'] = revisits['user_id'].map(focus_time.groupby('user_id')['total_before'].mean())\n",
    "revisits['mean_rating'] = revisits['user_id'].map(ratings.groupby('user_id')['rating_before'].median())\n",
    "\n",
    "click_rating = revisits[revisits['element'].isin(['genderRatingPoints', 'raceRatingPoints'])]\n",
    "hover_rating = logs2_hover[logs2_hover['element'].isin(['rating_race', 'rating_gender'])]\n",
    "\n",
    "click_time = revisits[revisits['element'].isin(['genderTimePoints', 'raceTimePoints'])]\n",
    "hover_time = logs2_hover[logs2_hover['element'].isin(['time_race', 'time_gender'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of applicants who were hovered that were rated lower than average:  145\n",
      "Number of applicants who were revisited that were rated lower than average:  9\n",
      "Number of applicants who were hovered that were spent less time than average:  247\n",
      "Number of applicants who were revisited that were spent less time than average:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of applicants who were hovered that were rated lower than average: \",\n",
    "       len(hover_rating[hover_rating['rating'] < hover_rating['mean_rating']]))\n",
    "\n",
    "print(\"Number of applicants who were revisited that were rated lower than average: \",\n",
    "       len(click_rating[click_rating['rating'] < click_rating['mean_rating']]))\n",
    "\n",
    "print(\"Number of applicants who were hovered that were spent less time than average: \",\n",
    "       len(hover_time[hover_time['focus_time'] < hover_time['mean_time']]))\n",
    "\n",
    "print(\"Number of applicants who were revisited that were spent less time than average: \",\n",
    "       len(click_time[click_time['focus_time'] < click_time['mean_time']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rating changes:  26\n",
      "Number of upgrades:  19\n",
      "Number of downgrades:  7\n",
      "Number of users who changed their ratings:  9\n"
     ]
    }
   ],
   "source": [
    "# Rating changes\n",
    "rating_changes = ratings[ratings['rating_change']!=0]\n",
    "\n",
    "print(\"Total number of rating changes: \", rating_changes.shape[0])\n",
    "\n",
    "print(\"Number of upgrades: \", len(rating_changes[rating_changes['rating_change'] > 0]))\n",
    "\n",
    "print(\"Number of downgrades: \", len(rating_changes[rating_changes['rating_change'] < 0]))\n",
    "\n",
    "print(\"Number of users who changed their ratings: \", len(rating_changes['user_id'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P69 time spent by race before and after: \n",
      "        total_before\n",
      "RACE               \n",
      "Black      1.843147\n",
      "White      2.245006 \n",
      "        total_after\n",
      "RACE              \n",
      "Black     2.292156\n",
      "White     2.407522\n",
      "\n",
      "P69 rating by race before and after: \n",
      "        rating_before\n",
      "RACE                \n",
      "Black      72.333333\n",
      "White      78.000000 \n",
      "        rating_after\n",
      "RACE               \n",
      "Black     74.166667\n",
      "White     77.666667\n",
      "\n",
      "P40 rating by gender before and after: \n",
      "             rating_before\n",
      "GENDER                   \n",
      "Female              64.75\n",
      "Male                83.75\n",
      "Non-binary          67.25 \n",
      "             rating_after\n",
      "GENDER                  \n",
      "Female             67.25\n",
      "Male               64.00\n",
      "Non-binary         70.25\n"
     ]
    }
   ],
   "source": [
    "# Rating and time spent changes of P69 and P40\n",
    "ratings_merged = pd.merge(ratings, applications[['applicant_id', 'GENDER', 'RACE']], on='applicant_id')\n",
    "time_merged = pd.merge(focus_time, applications[['applicant_id', 'GENDER', 'RACE']], on='applicant_id')\n",
    "rating_changes_p69 = ratings_merged[ratings_merged['user_id'] == 69]\n",
    "time_changes_p69 = time_merged[time_merged['user_id'] == 69]  \n",
    "rating_changes_p40 = ratings_merged[ratings_merged['user_id'] == 40]\n",
    "\n",
    "print(\"P69 time spent by race before and after: \\n\", \n",
    "      time_changes_p69[['RACE','total_before']].groupby('RACE').mean(),  \n",
    "      \"\\n\",\n",
    "      time_changes_p69[['RACE','total_after']].groupby('RACE').mean()\n",
    "      )\n",
    "\n",
    "print(\"\\nP69 rating by race before and after: \\n\", \n",
    "      rating_changes_p69[['RACE','rating_before']].groupby('RACE').mean(),  \n",
    "      \"\\n\",\n",
    "      rating_changes_p69[['RACE','rating_after']].groupby('RACE').mean()\n",
    "      )\n",
    "\n",
    "print(\"\\nP40 rating by gender before and after: \\n\", \n",
    "      rating_changes_p40[['GENDER','rating_before']].groupby('GENDER').mean(),  \n",
    "      \"\\n\",\n",
    "      rating_changes_p40[['GENDER','rating_after']].groupby('GENDER').mean()\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
